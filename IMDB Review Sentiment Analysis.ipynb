{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T02:30:23.374032Z",
     "start_time": "2018-03-13T02:30:23.369412Z"
    }
   },
   "source": [
    "# Sentiment Analysis using Word Embeddings\n",
    "Sentiment analysis is...\n",
    "\n",
    "In this notebook we are going to use the IMDB Review dataset compiled by Stanford (add a link here). This dataset has [enter number here] reviews, half of which are used for training and the other half for testing. This is a binary classification problem where the classes are either 'positive' or 'negative'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:53:30.459334Z",
     "start_time": "2018-03-14T23:53:30.448868Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, RNN\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IMDB dataset is has been downloaded from [here](http://ai.stanford.edu/~amaas/data/sentiment/) and unzipped into the 'data' directory.\n",
    "\n",
    "Note: Keras has a built-in function to access this database but we want to manually perform the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:45:18.620853Z",
     "start_time": "2018-03-14T23:45:18.617095Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/train'\n",
    "TEST_PATH = 'data/test'\n",
    "SEED = 2018\n",
    "VOCAB_SIZE = 100\n",
    "MAX_REVIEW_LEN = 250\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:45:20.542394Z",
     "start_time": "2018-03-14T23:45:20.530076Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_x_y(file_path):\n",
    "    files = {}\n",
    "    files['pos'] = glob(os.path.join(file_path, 'pos', '*.txt'))\n",
    "    files['neg'] = glob(os.path.join(file_path, 'neg', '*.txt'))\n",
    "    \n",
    "    sentiment_map = {'pos': 1, 'neg': 0}\n",
    "    x = []\n",
    "    y = []\n",
    "    for sentiment in files:\n",
    "        for file_name in files[sentiment]:\n",
    "            temp_ = []\n",
    "            with open(file_name) as file_:\n",
    "                temp_ = file_.read()\n",
    "            x.append(temp_)\n",
    "            y.append(sentiment_map[sentiment])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:45:21.899501Z",
     "start_time": "2018-03-14T23:45:20.929196Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the text data\n",
    "x_train, y_train = get_x_y(TRAIN_PATH)\n",
    "x_test, y_test = get_x_y(TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data now looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:28:24.243276Z",
     "start_time": "2018-03-14T23:28:24.237049Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this type of data makes sense to humans, we need to convert the (in this case) English sentences into sequences of numbers. This can be done by using a tool provided by Keras called a 'Tokenizer'. This transforms strings into sequences of numbers where words are mapped to numbers corresponding to their overall frequency. For example, if the word 'a' is the most common word and 'this' is the second most common the sentence: 'This is a dog.' Would become [2, 0, 1, 0], where '0' is a placeholder for any word not in the tokenizer. We also need to make sure all of our sequences are the same length. we can choose a length that makes sense and pad the sequences with zeros to that length.\n",
    "\n",
    "Note: We have already did some transformations by converting 'pos' => 0, and 'neg' => 1 when we read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set()\n",
    "\n",
    "for review in x_train:\n",
    "    review_words = review.split()\n",
    "    for word in review_words:\n",
    "        unique_words.add(word.lower())\n",
    "\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:45:27.744118Z",
     "start_time": "2018-03-14T23:45:23.985342Z"
    }
   },
   "outputs": [],
   "source": [
    "time_start = datetime.now()\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "print('time to fit: ' + str(datetime.now() - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:45:32.803409Z",
     "start_time": "2018-03-14T23:45:27.745654Z"
    }
   },
   "outputs": [],
   "source": [
    "time_start = datetime.now()\n",
    "\n",
    "# Fit our training data\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_train = pad_sequences(x_train, maxlen=MAX_REVIEW_LEN)\n",
    "\n",
    "# Fit our testing data\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test = pad_sequences(x_test, maxlen=MAX_REVIEW_LEN)\n",
    "\n",
    "print('time to fit: ' + str(datetime.now() - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying our tokenizer the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:28:37.791165Z",
     "start_time": "2018-03-14T23:28:37.788198Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:28:40.511952Z",
     "start_time": "2018-03-14T23:28:40.486615Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:28:41.193086Z",
     "start_time": "2018-03-14T23:28:41.029381Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SGDClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T22:29:57.888054Z",
     "start_time": "2018-03-14T22:29:57.881616Z"
    }
   },
   "outputs": [],
   "source": [
    "def basic_lstm_model(embedding_vector_length=32, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(VOCAB_SIZE, embedding_vector_length, input_length=MAX_REVIEW_LEN))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T22:29:57.893535Z",
     "start_time": "2018-03-14T22:29:57.889614Z"
    }
   },
   "outputs": [],
   "source": [
    "model = basic_lstm_model()\n",
    "model.fit(x_train, y_train, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE)\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 100\n",
    "MAX_REVIEW_LEN = 250\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "EMBED_LENGTH = 32\n",
    "DROPOUT_RATE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared data in 0:00:10.201403\n"
     ]
    }
   ],
   "source": [
    "time_start = datetime.now()\n",
    "\n",
    "# Read in the text data\n",
    "x_train, y_train = get_x_y(TRAIN_PATH)\n",
    "x_test, y_test = get_x_y(TEST_PATH)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Fit our training data\n",
    "x_train_sequence = tokenizer.texts_to_sequences(x_train)\n",
    "x_train_pad = pad_sequences(x_train_sequence, maxlen=MAX_REVIEW_LEN)\n",
    "\n",
    "# Fit our testing data\n",
    "x_test_sequence = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_pad = pad_sequences(x_test_sequence, maxlen=MAX_REVIEW_LEN)\n",
    "\n",
    "print('Prepared data in ' + str(datetime.now() - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for testing\n",
    "x_train_pad_sub, y_train_sub = resample(x_train_pad, y_train, replace=False, n_samples=5000, random_state=SEED)\n",
    "\n",
    "x_test_pad_sub, y_test_sub = resample(x_test_pad, y_test, replace=False, n_samples=5000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(num_epochs=5, batch_size=32, embed_length=32, dropout_rate=0.2):\n",
    "    time_start = datetime.now()\n",
    "    model = basic_lstm_model(embedding_vector_length=embed_length, dropout_rate=dropout_rate)\n",
    "    model.fit(x_train_pad_sub, y_train_sub, epochs=num_epochs, batch_size=batch_size)\n",
    "    scores = model.evaluate(x_test_pad_sub, y_test_sub, verbose=0)\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "    return scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for testing\n",
    "epochs = range(1, 6)\n",
    "scores = []\n",
    "for epoch in epochs:\n",
    "    print('epoch(s): ' + str(epoch))\n",
    "    scores.append(train_and_evaluate_model(num_epochs=epoch, batch_size=32, embed_length=32, dropout_rate=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5]\n",
    "plt.bar(x, scores)\n",
    "\n",
    "plt.xlim([0, len(x)+1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Number of Epochs vs Accuracy')\n",
    "plt.legend(['5k samples train/validate'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 100\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "EMBED_LENGTH = 32\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "\n",
    "# Read in the text data - this does not change so can/should be outside the function for speed\n",
    "x_train_raw, y_train_raw = get_x_y(TRAIN_PATH)\n",
    "x_test_raw, y_test_raw = get_x_y(TEST_PATH)\n",
    "\n",
    "def prep_data(vocab_size=100, max_review_len=150):\n",
    "    time_start = datetime.now()\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    \n",
    "    # Fit our training data\n",
    "    x_train_sequence = tokenizer.texts_to_sequences(x_train_raw)\n",
    "    x_train_pad = pad_sequences(x_train_sequence, maxlen=max_review_len)\n",
    "\n",
    "    # Fit our testing data\n",
    "    x_test_sequence = tokenizer.texts_to_sequences(x_test_raw)\n",
    "    x_test_pad = pad_sequences(x_test_sequence, maxlen=max_review_len)\n",
    "\n",
    "    # Subset for testing\n",
    "    x_train_pad_sub, y_train_sub = resample(x_train_pad, y_train_raw, replace=False, n_samples=5000, random_state=SEED)\n",
    "    x_test_pad_sub, y_test_sub = resample(x_test_pad, y_test_raw, replace=False, n_samples=5000, random_state=SEED)\n",
    "\n",
    "    print('Prepared data in ' + str(datetime.now() - time_start))\n",
    "    return x_train_pad_sub, y_train_sub, x_test_pad_sub, y_test_sub\n",
    "\n",
    "def basic_lstm_model(\n",
    "    embedding_vector_length=32,\n",
    "    dropout_rate=0.2, \n",
    "    vocab_size=100, \n",
    "    max_review_len=150,\n",
    "    lstm_len=100\n",
    "):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_vector_length, input_length=max_review_len))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(lstm_len))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_model(\n",
    "    x_train=x_train_pad_sub,\n",
    "    y_train=y_train_sub,\n",
    "    x_test=x_train_pad_sub,\n",
    "    y_test=y_test_sub,\n",
    "    num_epochs=5,\n",
    "    batch_size=32,\n",
    "    max_review_len=100,\n",
    "    embed_length=32,\n",
    "    vocab_size=100,\n",
    "    verbose=1\n",
    "):\n",
    "    time_start = datetime.now()\n",
    "    model = basic_lstm_model(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_vector_length=embed_length,\n",
    "        max_review_len=max_review_len\n",
    "    )\n",
    "    model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, verbose=verbose)\n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "    return scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Prepared data in 0:00:08.914571\n",
      "5000/5000 [==============================] - 1s 289us/step\n",
      "Accuracy: 60.58%\n",
      "25\n",
      "Prepared data in 0:00:08.946276\n",
      "5000/5000 [==============================] - 2s 432us/step\n",
      "Accuracy: 64.44%\n",
      "50\n",
      "Prepared data in 0:00:09.030706\n",
      "5000/5000 [==============================] - 3s 600us/step\n",
      "Accuracy: 68.54%\n",
      "100\n",
      "Prepared data in 0:00:09.293315\n",
      "5000/5000 [==============================] - 5s 974us/step\n",
      "Accuracy: 68.00%\n",
      "150\n",
      "Prepared data in 0:00:09.178606\n",
      "5000/5000 [==============================] - 7s 1ms/step\n",
      "Accuracy: 68.36%\n",
      "200\n",
      "Prepared data in 0:00:09.172425\n",
      "5000/5000 [==============================] - 8s 2ms/step\n",
      "Accuracy: 70.56%\n",
      "250\n",
      "Prepared data in 0:00:09.195947\n",
      "5000/5000 [==============================] - 10s 2ms/step\n",
      "Accuracy: 65.20%\n"
     ]
    }
   ],
   "source": [
    "max_review_lengths = [10, 25, 50, 100, 150, 200, 250]\n",
    "scores = []\n",
    "\n",
    "for max_review in max_review_lengths:\n",
    "    print(max_review)\n",
    "    x_train_pad_sub, y_train_sub, x_test_pad_sub, y_test_sub = prep_data(\n",
    "        vocab_size=100,\n",
    "        max_review_len=max_review\n",
    "    )\n",
    "    \n",
    "    scores.append(\n",
    "        train_and_evaluate_model(\n",
    "            x_train=x_train_pad_sub,\n",
    "            y_train=y_train_sub,\n",
    "            x_test=x_test_pad_sub,\n",
    "            y_test=y_test_sub,\n",
    "            num_epochs=2,\n",
    "            max_review_len=max_review,\n",
    "            verbose=0\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Prepared data in 0:00:08.978308\n",
      "5000/5000 [==============================] - 2s 327us/step\n",
      "Accuracy: 62.54%\n",
      "25\n",
      "Prepared data in 0:00:09.026532\n",
      "5000/5000 [==============================] - 2s 467us/step\n",
      "Accuracy: 67.90%\n",
      "50\n",
      "Prepared data in 0:00:09.117182\n",
      "5000/5000 [==============================] - 3s 645us/step\n",
      "Accuracy: 72.68%\n",
      "100\n",
      "Prepared data in 0:00:09.169314\n",
      "5000/5000 [==============================] - 5s 1ms/step\n",
      "Accuracy: 74.22%\n",
      "150\n",
      "Prepared data in 0:00:09.203932\n",
      "5000/5000 [==============================] - 7s 1ms/step\n",
      "Accuracy: 71.78%\n",
      "200\n",
      "Prepared data in 0:00:09.311876\n"
     ]
    }
   ],
   "source": [
    "max_review_lengths = [10, 25, 50, 100, 150, 200, 250]\n",
    "scores_250 = []\n",
    "\n",
    "for max_review in max_review_lengths:\n",
    "    print(max_review)\n",
    "    x_train_pad_sub, y_train_sub, x_test_pad_sub, y_test_sub = prep_data(\n",
    "        vocab_size=250,\n",
    "        max_review_len=max_review\n",
    "    )\n",
    "    \n",
    "    scores_250.append(\n",
    "        train_and_evaluate_model(\n",
    "            x_train=x_train_pad_sub,\n",
    "            y_train=y_train_sub,\n",
    "            x_test=x_test_pad_sub,\n",
    "            y_test=y_test_sub,\n",
    "            num_epochs=2,\n",
    "            max_review_len=max_review,\n",
    "            vocab_size=250,\n",
    "            verbose=0\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "x_range = np.arange(7)\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x_range, scores, width)\n",
    "plt.bar(x_range + width, scores_250, width)\n",
    "\n",
    "plt.xticks(x_range, max_review_lengths)\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Max Review Lengths')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Length of Reviews vs Accuracy (5k Samples Used)')\n",
    "plt.legend(['Vocab Size 100', 'Vocab Size 250'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
