{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T02:30:23.374032Z",
     "start_time": "2018-03-13T02:30:23.369412Z"
    }
   },
   "source": [
    "# Sentiment Analysis using Word Embeddings\n",
    "Sentiment analysis is...\n",
    "\n",
    "In this notebook we are going to use the IMDB Review dataset compiled by Stanford (add a link here). This dataset has [enter number here] reviews, half of which are used for training and the other half for testing. This is a binary classification problem where the classes are either 'positive' or 'negative'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:53:30.459334Z",
     "start_time": "2018-03-14T23:53:30.448868Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, RNN\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IMDB dataset is has been downloaded from [here](http://ai.stanford.edu/~amaas/data/sentiment/) and unzipped into the 'data' directory.\n",
    "\n",
    "Note: Keras has a built-in function to access this database but we want to manually perform the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:45:18.620853Z",
     "start_time": "2018-03-14T23:45:18.617095Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/train'\n",
    "TEST_PATH = 'data/test'\n",
    "SEED = 2018\n",
    "VOCAB_SIZE = 100\n",
    "MAX_REVIEW_LEN = 250\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:45:20.542394Z",
     "start_time": "2018-03-14T23:45:20.530076Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_x_y(file_path):\n",
    "    files = {}\n",
    "    files['pos'] = glob(os.path.join(file_path, 'pos', '*.txt'))\n",
    "    files['neg'] = glob(os.path.join(file_path, 'neg', '*.txt'))\n",
    "    \n",
    "    sentiment_map = {'pos': 1, 'neg': 0}\n",
    "    x = []\n",
    "    y = []\n",
    "    for sentiment in files:\n",
    "        for file_name in files[sentiment]:\n",
    "            temp_ = []\n",
    "            with open(file_name) as file_:\n",
    "                temp_ = file_.read()\n",
    "            x.append(temp_)\n",
    "            y.append(sentiment_map[sentiment])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:45:21.899501Z",
     "start_time": "2018-03-14T23:45:20.929196Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the text data\n",
    "x_train, y_train = get_x_y(TRAIN_PATH)\n",
    "x_test, y_test = get_x_y(TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data now looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:28:24.243276Z",
     "start_time": "2018-03-14T23:28:24.237049Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this type of data makes sense to humans, we need to convert the (in this case) English sentences into sequences of numbers. This can be done by using a tool provided by Keras called a 'Tokenizer'. This transforms strings into sequences of numbers where words are mapped to numbers corresponding to their overall frequency. For example, if the word 'a' is the most common word and 'this' is the second most common the sentence: 'This is a dog.' Would become [2, 0, 1, 0], where '0' is a placeholder for any word not in the tokenizer. We also need to make sure all of our sequences are the same length. we can choose a length that makes sense and pad the sequences with zeros to that length.\n",
    "\n",
    "Note: We have already did some transformations by converting 'pos' => 0, and 'neg' => 1 when we read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set()\n",
    "\n",
    "for review in x_train:\n",
    "    review_words = review.split()\n",
    "    for word in review_words:\n",
    "        unique_words.add(word.lower())\n",
    "\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:45:27.744118Z",
     "start_time": "2018-03-14T23:45:23.985342Z"
    }
   },
   "outputs": [],
   "source": [
    "time_start = datetime.now()\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "print('time to fit: ' + str(datetime.now() - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:45:32.803409Z",
     "start_time": "2018-03-14T23:45:27.745654Z"
    }
   },
   "outputs": [],
   "source": [
    "time_start = datetime.now()\n",
    "\n",
    "# Fit our training data\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_train = pad_sequences(x_train, maxlen=MAX_REVIEW_LEN)\n",
    "\n",
    "# Fit our testing data\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test = pad_sequences(x_test, maxlen=MAX_REVIEW_LEN)\n",
    "\n",
    "print('time to fit: ' + str(datetime.now() - time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying our tokenizer the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:28:37.791165Z",
     "start_time": "2018-03-14T23:28:37.788198Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:28:40.511952Z",
     "start_time": "2018-03-14T23:28:40.486615Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T23:28:41.193086Z",
     "start_time": "2018-03-14T23:28:41.029381Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SGDClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T22:29:57.888054Z",
     "start_time": "2018-03-14T22:29:57.881616Z"
    }
   },
   "outputs": [],
   "source": [
    "def basic_lstm_model(embedding_vector_length=32, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(VOCAB_SIZE, embedding_vector_length, input_length=MAX_REVIEW_LEN))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-14T22:29:57.893535Z",
     "start_time": "2018-03-14T22:29:57.889614Z"
    }
   },
   "outputs": [],
   "source": [
    "model = basic_lstm_model()\n",
    "model.fit(x_train, y_train, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE)\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 100\n",
    "MAX_REVIEW_LEN = 250\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "EMBED_LENGTH = 32\n",
    "DROPOUT_RATE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared data in 0:00:10.006028\n"
     ]
    }
   ],
   "source": [
    "time_start = datetime.now()\n",
    "\n",
    "# Read in the text data\n",
    "x_train, y_train = get_x_y(TRAIN_PATH)\n",
    "x_test, y_test = get_x_y(TEST_PATH)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Fit our training data\n",
    "x_train_sequence = tokenizer.texts_to_sequences(x_train)\n",
    "x_train_pad = pad_sequences(x_train_sequence, maxlen=MAX_REVIEW_LEN)\n",
    "\n",
    "# Fit our testing data\n",
    "x_test_sequence = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_pad = pad_sequences(x_test_sequence, maxlen=MAX_REVIEW_LEN)\n",
    "\n",
    "print('Prepared data in ' + str(datetime.now() - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for testing\n",
    "x_train_pad_sub, y_train_sub = resample(x_train_pad, y_train, replace=False, n_samples=5000, random_state=SEED)\n",
    "\n",
    "x_test_pad_sub, y_test_sub = resample(x_test_pad, y_test, replace=False, n_samples=5000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(num_epochs=5, batch_size=32, embed_length=32, dropout_rate=0.2):\n",
    "    time_start = datetime.now()\n",
    "    model = basic_lstm_model(embedding_vector_length=embed_length, dropout_rate=dropout_rate)\n",
    "    model.fit(x_train_pad_sub, y_train_sub, epochs=num_epochs, batch_size=batch_size)\n",
    "    scores = model.evaluate(x_test_pad_sub, y_test_sub, verbose=0)\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "    return scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for testing\n",
    "epochs = range(1, 6)\n",
    "scores = []\n",
    "for epoch in epochs:\n",
    "    print('epoch(s): ' + str(epoch))\n",
    "    scores.append(train_and_evaluate_model(num_epochs=epoch, batch_size=32, embed_length=32, dropout_rate=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5]\n",
    "plt.bar(x, scores)\n",
    "\n",
    "plt.xlim([0, len(x)+1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Number of Epochs vs Accuracy')\n",
    "plt.legend(['5k samples train/validate'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 100\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "EMBED_LENGTH = 32\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "\n",
    "# Read in the text data - this does not change so can/should be outside the function for speed\n",
    "x_train_raw, y_train_raw = get_x_y(TRAIN_PATH)\n",
    "x_test_raw, y_test_raw = get_x_y(TEST_PATH)\n",
    "\n",
    "def prep_data(vocab_size=100, max_review_len=150):\n",
    "    time_start = datetime.now()\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    \n",
    "    # Fit our training data\n",
    "    x_train_sequence = tokenizer.texts_to_sequences(x_train_raw)\n",
    "    x_train_pad = pad_sequences(x_train_sequence, maxlen=max_review_len)\n",
    "\n",
    "    # Fit our testing data\n",
    "    x_test_sequence = tokenizer.texts_to_sequences(x_test_raw)\n",
    "    x_test_pad = pad_sequences(x_test_sequence, maxlen=max_review_len)\n",
    "\n",
    "    # Subset for testing\n",
    "    x_train_pad_sub, y_train_sub = resample(x_train_pad, y_train_raw, replace=False, n_samples=5000, random_state=SEED)\n",
    "    x_test_pad_sub, y_test_sub = resample(x_test_pad, y_test_raw, replace=False, n_samples=5000, random_state=SEED)\n",
    "\n",
    "    print('Prepared data in ' + str(datetime.now() - time_start))\n",
    "    return x_train_pad_sub, y_train_sub, x_test_pad_sub, y_test_sub\n",
    "\n",
    "def basic_lstm_model(\n",
    "    embedding_vector_length=32,\n",
    "    dropout_rate=0.2, \n",
    "    vocab_size=100, \n",
    "    max_review_len=150,\n",
    "    lstm_len=100\n",
    "):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_vector_length, input_length=max_review_len))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(lstm_len))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_model(\n",
    "    x_train=x_train_pad_sub,\n",
    "    y_train=y_train_sub,\n",
    "    x_test=x_train_pad_sub,\n",
    "    y_test=y_test_sub,\n",
    "    num_epochs=5,\n",
    "    batch_size=32,\n",
    "    max_review_len=100,\n",
    "    embed_length=32,\n",
    "    vocab_size=100\n",
    "):\n",
    "    time_start = datetime.now()\n",
    "    model = basic_lstm_model(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_vector_length=embed_length,\n",
    "        max_review_len=max_review_len\n",
    "    )\n",
    "    model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size)\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "    return scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Prepared data in 0:00:08.873295\n",
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 4s 713us/step - loss: 0.6810 - acc: 0.5578\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 3s 602us/step - loss: 0.6544 - acc: 0.6168\n",
      "Accuracy: 61.08%\n",
      "25\n",
      "Prepared data in 0:00:08.922992\n",
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 0.6750 - acc: 0.5742\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.6325 - acc: 0.6398\n",
      "Accuracy: 63.70%\n",
      "50\n",
      "Prepared data in 0:00:08.833622\n",
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 10s 2ms/step - loss: 0.6636 - acc: 0.5906\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 10s 2ms/step - loss: 0.6048 - acc: 0.6706\n",
      "Accuracy: 67.20%\n",
      "100\n",
      "Prepared data in 0:00:08.914771\n",
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 0.6679 - acc: 0.5782\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 18s 4ms/step - loss: 0.5978 - acc: 0.6814\n",
      "Accuracy: 68.24%\n",
      "150\n",
      "Prepared data in 0:00:08.983550\n",
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 28s 6ms/step - loss: 0.6773 - acc: 0.5682\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 27s 5ms/step - loss: 0.6021 - acc: 0.6810\n",
      "Accuracy: 69.42%\n",
      "200\n",
      "Prepared data in 0:00:09.200115\n",
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.6803 - acc: 0.5628\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.6098 - acc: 0.6726\n",
      "Accuracy: 70.00%\n",
      "250\n",
      "Prepared data in 0:00:09.068862\n",
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 45s 9ms/step - loss: 0.6923 - acc: 0.5552\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 44s 9ms/step - loss: 0.6433 - acc: 0.6388\n",
      "Accuracy: 69.82%\n"
     ]
    }
   ],
   "source": [
    "max_review_lengths = [10, 25, 50, 100, 150, 200, 250]\n",
    "scores = []\n",
    "\n",
    "for max_review in max_review_lengths:\n",
    "    print(max_review)\n",
    "    x_train_pad_sub, y_train_sub, x_test_pad_sub, y_test_sub = prep_data(\n",
    "        vocab_size=100,\n",
    "        max_review_len=max_review\n",
    "    )\n",
    "    \n",
    "    scores.append(\n",
    "        train_and_evaluate_model(\n",
    "            x_train=x_train_pad_sub,\n",
    "            y_train=y_train_sub,\n",
    "            x_test=x_test_pad_sub,\n",
    "            y_test=y_test_sub,\n",
    "            num_epochs=2,\n",
    "            max_review_len=max_review\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(1,8), scores)\n",
    "plt.xticks(range(1,8), max_review_lengths)\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Max Review Lengths')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Length of Reviews vs Accuracy')\n",
    "plt.legend(['5k samples Vocab Size 100'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Prepared data in 0:00:08.765916\n",
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 4s 810us/step - loss: 0.6771 - acc: 0.5654\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 3s 635us/step - loss: 0.6326 - acc: 0.6362\n",
      "Accuracy: 62.54%\n",
      "25\n",
      "Prepared data in 0:00:09.082967\n",
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.6676 - acc: 0.5850\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.6017 - acc: 0.6800\n",
      "Accuracy: 67.70%\n",
      "50\n",
      "Prepared data in 0:00:08.932994\n"
     ]
    }
   ],
   "source": [
    "max_review_lengths = [10, 25, 50, 100, 150, 200, 250]\n",
    "scores_250 = []\n",
    "\n",
    "for max_review in max_review_lengths:\n",
    "    print(max_review)\n",
    "    x_train_pad_sub, y_train_sub, x_test_pad_sub, y_test_sub = prep_data(\n",
    "        vocab_size=250,\n",
    "        max_review_len=max_review\n",
    "    )\n",
    "    \n",
    "    scores.append(\n",
    "        train_and_evaluate_model(\n",
    "            x_train=x_train_pad_sub,\n",
    "            y_train=y_train_sub,\n",
    "            x_test=x_test_pad_sub,\n",
    "            y_test=y_test_sub,\n",
    "            num_epochs=2,\n",
    "            max_review_len=max_review,\n",
    "            vocab_size=250\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
